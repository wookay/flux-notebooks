{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/MikeInnes/Flux.jl/blob/master/examples/MNIST.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Flux, MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Array{Tuple{Array{Float64,1},Array{Int64,1}},1}:\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
       " ⋮                                                                                                                                        \n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(trainfeatures(i), onehot(trainlabel(i), 0:9)) for i = 1:60_000]\n",
    "train = data[1:50_000]\n",
    "test = data[50_001:60_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flux.Chain(Any[Flux.Input{1}((784,)), Flux.Affine(Param(784, 128), Param(1, 128)), Flux.relu, Flux.Affine(Param(128, 64), Param(1, 64)), Flux.relu, Flux.Affine(Param(64, 10), Param(1, 10)), Flux.softmax], 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  Input(784),\n",
    "  Affine(128), relu,\n",
    "  Affine( 64), relu,\n",
    "  Affine( 10), softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-13 22:42:28.665803: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-03-13 22:42:28.665844: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-03-13 22:42:28.665848: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-03-13 22:42:28.665853: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Flux.TF.Model(Flux.Chain(Any[Flux.Input{1}((784,)), Flux.Affine(Param(784, 128), Param(1, 128)), Flux.relu, Flux.Affine(Param(128, 64), Param(1, 64)), Flux.relu, Flux.Affine(Param(64, 10), Param(1, 10)), Flux.softmax], 10), Session(Ptr{Void} @0x000000014805a6b0), Dict{Flux.Param,TensorFlow.Tensor}(Pair{Flux.Param,TensorFlow.Tensor}(Param(1, 128), <Tensor node_2:1 shape=(1, 128) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(1, 64), <Tensor node_4:1 shape=(1, 64) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(128, 64), <Tensor node_3:1 shape=(128, 64) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(64, 10), <Tensor node_5:1 shape=(64, 10) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(784, 128), <Tensor node:1 shape=(784, 128) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(1, 10), <Tensor node_6:1 shape=(1, 10) dtype=Float32>)), Dict{Any,Any}(Pair{Any,Any}(\"TensorFlow.nn.relu_2\", Any[(Flux.Affine(Param(64, 10), Param(1, 10)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"TensorFlow.nn.relu\", Any[(Flux.Affine(Param(128, 64), Param(1, 64)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"add\", Any[(Flux.Affine(Param(784, 128), Param(1, 128)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"matmul_3\", Any[(Flux.Affine(Param(64, 10), Param(1, 10)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"matmul_2\", Any[(Flux.Affine(Param(128, 64), Param(1, 64)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"add_3\", Any[(Flux.Affine(Param(64, 10), Param(1, 10)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"add_2\", Any[(Flux.Affine(Param(128, 64), Param(1, 64)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"placeholder\", Any[(Flux.Affine(Param(784, 128), Param(1, 128)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"TensorFlow.nn.softmax\", Any[]),Pair{Any,Any}(\"matmul\", Any[(Flux.Affine(Param(784, 128), Param(1, 128)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))])…), TensorFlow.Tensor[<Tensor placeholder:1 shape=unknown dtype=Float32>], <Tensor TensorFlow.nn.softmax:1 shape=unknown dtype=Float32>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 0.0954587\n",
       " 0.107971 \n",
       " 0.101638 \n",
       " 0.101143 \n",
       " 0.104277 \n",
       " 0.0906427\n",
       " 0.10357  \n",
       " 0.106997 \n",
       " 0.0908182\n",
       " 0.0974839"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33m`invoke(f, (types...), ...)` is deprecated, use `invoke(f, Tuple{types...}, ...)` instead\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:64\u001b[22m\u001b[22m\n",
      " [2] \u001b[1m(::Flux.TF.##13#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Tensor\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mbroadcast\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Function, ::TensorFlow.Tensor\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./broadcast.jl:415\u001b[22m\u001b[22m\n",
      " [4] \u001b[1m#12\u001b[22m\u001b[22m at \u001b[1m/Users/wookyoung/.julia/v0.6/Flux/src/backend/tensorflow/model.jl:52\u001b[22m\u001b[22m [inlined]\n",
      " [5] \u001b[1m#train!#9\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64, ::Float64, ::Flux.TF.##12#16, ::TensorFlow.train.GradientDescentOptimizer, ::Function, ::Flux.TF.Model, ::Array{Tuple{Array{Float64,1},Array{Int64,1}},1}, ::Array{Tuple{Array{Float64,1},Array{Int64,1}},1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/wookyoung/.julia/v0.6/Flux/src/backend/tensorflow/model.jl:56\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m(::Flux.#kw##train!)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Flux.#train!, ::Flux.TF.Model, ::Array{Tuple{Array{Float64,1},Array{Int64,1}},1}, ::Array{Tuple{Array{Float64,1},Array{Int64,1}},1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [7] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:485\u001b[22m\u001b[22m\n",
      " [8] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/wookyoung/.julia/v0.6/IJulia/src/execute_request.jl:156\u001b[22m\u001b[22m\n",
      " [9] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/wookyoung/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [10] \u001b[1m(::IJulia.##9#12)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[6], in expression starting on line 1\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 1\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = Float32[0.0954587 0.107971 0.101638 0.101143 0.104277 0.0906427 0.10357 0.106997 0.0908182 0.0974839]\n",
      "accuracy(m, test) = 0.1588\n",
      "y = Float32[0.112878 0.0851877 0.0908585 0.091816 0.10395 0.0802012 0.112048 0.135987 0.0885109 0.0985625]\n",
      "accuracy(m, test) = 0.3869\n",
      "y = Float32[0.0878864 0.0334534 0.115824 0.483959 0.0167746 0.0472774 0.032622 0.0491337 0.100671 0.0323983]\n",
      "accuracy(m, test) = 0.6299\n",
      "y = Float32[0.0571796 0.000821835 0.0114025 0.0299696 0.131877 0.39911 0.0777704 0.00316711 0.149018 0.139684]\n",
      "accuracy(m, test) = 0.844\n",
      "y = Float32[0.0153415 9.35665f-7 4.33114f-5 0.00266004 0.000563149 0.964867 0.00390603 1.49702f-6 0.011593 0.00102394]\n",
      "accuracy(m, test) = 0.8692\n",
      "y = Float32[0.00115191 0.00625591 0.0493428 0.25009 0.00154897 0.00498523 0.000166904 0.41842 0.024457 0.243581]\n",
      "accuracy(m, test) = 0.8755\n",
      "y = Float32[0.00032824 0.000564357 0.00251635 0.983561 5.21648f-6 0.00675256 1.07315f-5 0.000581958 0.00496591 0.00071412]\n",
      "accuracy(m, test) = 0.893\n",
      "y = Float32[2.12749f-6 0.9926 0.000598531 0.00254765 8.60559f-5 0.000377181 0.000571533 9.59039f-5 0.00287487 0.000246019]\n",
      "accuracy(m, test) = 0.9033\n",
      "y = Float32[2.01636f-6 1.19481f-6 6.08354f-6 2.1235f-5 7.96f-7 8.55657f-6 6.12426f-9 0.99449 0.000234788 0.00523507]\n",
      "accuracy(m, test) = 0.903\n",
      "y = Float32[0.000522817 3.28366f-5 0.00020933 0.814079 3.70592f-6 0.174018 1.30033f-5 2.09987f-5 0.0109461 0.000153725]\n",
      "accuracy(m, test) = 0.9059\n"
     ]
    }
   ],
   "source": [
    "Flux.train!(model, train, test, η = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 0.0131847  \n",
       " 1.57745f-6 \n",
       " 0.000494634\n",
       " 0.50863    \n",
       " 1.52883f-7 \n",
       " 0.47397    \n",
       " 1.40895f-5 \n",
       " 0.000332042\n",
       " 0.00323067 \n",
       " 0.000142051"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indmax(model(data[1][1])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using UnicodePlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[37m      Sparsity Pattern\n",
       "\u001b[39m\u001b[37m      ┌──────────────┐\u001b[39m    \n",
       "    \u001b[37m1\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[31m> 0\u001b[39m\n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⣤\u001b[39m\u001b[31m⣤\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⡶\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[34m< 0\u001b[39m\n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠻\u001b[39m\u001b[31m⢿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⡋\u001b[39m\u001b[31m⠛\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "   \u001b[37m\u001b[39m  \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠻\u001b[39m\u001b[31m⣷\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣄\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣀\u001b[39m\u001b[31m⣬\u001b[39m\u001b[31m⣽\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠆\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣀\u001b[39m\u001b[31m⣤\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠿\u001b[39m\u001b[31m⠛\u001b[39m\u001b[31m⠁\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "   \u001b[37m28\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⠉\u001b[39m\u001b[31m⠉\u001b[39m\u001b[31m⠉\u001b[39m\u001b[31m⠉\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "\u001b[37m      └──────────────┘\u001b[39m    \n",
       "\u001b[37m      1\u001b[39m\u001b[37m      \u001b[39m\u001b[37m       28\n",
       "\u001b[39m\u001b[37m         nz = 166\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy(reshape(data[1][1], (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[37m      Sparsity Pattern\n",
       "\u001b[39m\u001b[37m      ┌──────────────┐\u001b[39m    \n",
       "    \u001b[37m1\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[31m> 0\u001b[39m\n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⣠\u001b[39m\u001b[31m⣾\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣤\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[34m< 0\u001b[39m\n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣠\u001b[39m\u001b[31m⣾\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠿\u001b[39m\u001b[31m⠿\u001b[39m\u001b[31m⠛\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⡄\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "   \u001b[37m\u001b[39m  \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣸\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠋\u001b[39m\u001b[31m⠉\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⡇\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⡏\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⣴\u001b[39m\u001b[31m⡿\u001b[39m\u001b[31m⠛\u001b[39m\u001b[31m⠁\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⢿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠟\u001b[39m\u001b[31m⠋\u001b[39m\u001b[31m⠁\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "   \u001b[37m28\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "\u001b[37m      └──────────────┘\u001b[39m    \n",
       "\u001b[37m      1\u001b[39m\u001b[37m      \u001b[39m\u001b[37m       28\n",
       "\u001b[39m\u001b[37m         nz = 176\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy(reshape(data[2][1], (28,28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0-dev",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
