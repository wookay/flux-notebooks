{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/MikeInnes/Flux.jl/blob/master/examples/MNIST.jl\n",
    "- https://mikeinnes.github.io/Flux.jl/latest/examples/logreg.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Flux, MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Array{Tuple{Array{Float64,1},Array{Int64,1}},1}:\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
       " ⋮                                                                                                                                        \n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(trainfeatures(i), onehot(trainlabel(i), 0:9)) for i = 1:60_000]\n",
    "train = data[1:50_000]\n",
    "test = data[50_001:60_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flux.Chain(Any[Flux.Input{1}((784,)), Flux.Affine(Param(784, 128), Param(1, 128)), Flux.relu, Flux.Affine(Param(128, 64), Param(1, 64)), Flux.relu, Flux.Affine(Param(64, 10), Param(1, 10)), Flux.softmax], 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  Input(784),\n",
    "  Affine(128), relu,\n",
    "  Affine( 64), relu,\n",
    "  Affine( 10), softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-14 22:30:05.919437: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-03-14 22:30:05.919485: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-03-14 22:30:05.919489: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-03-14 22:30:05.919494: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Flux.TF.Model(Flux.Chain(Any[Flux.Input{1}((784,)), Flux.Affine(Param(784, 128), Param(1, 128)), Flux.relu, Flux.Affine(Param(128, 64), Param(1, 64)), Flux.relu, Flux.Affine(Param(64, 10), Param(1, 10)), Flux.softmax], 10), Session(Ptr{Void} @0x0000000143ab4f70), Dict{Flux.Param,TensorFlow.Tensor}(Pair{Flux.Param,TensorFlow.Tensor}(Param(64, 10), <Tensor node_5:1 shape=(64, 10) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(784, 128), <Tensor node:1 shape=(784, 128) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(128, 64), <Tensor node_3:1 shape=(128, 64) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(1, 128), <Tensor node_2:1 shape=(1, 128) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(1, 64), <Tensor node_4:1 shape=(1, 64) dtype=Float32>),Pair{Flux.Param,TensorFlow.Tensor}(Param(1, 10), <Tensor node_6:1 shape=(1, 10) dtype=Float32>)), Dict{Any,Any}(Pair{Any,Any}(\"TensorFlow.nn.relu_2\", Any[(Flux.Affine(Param(64, 10), Param(1, 10)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"TensorFlow.nn.relu\", Any[(Flux.Affine(Param(128, 64), Param(1, 64)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"add\", Any[(Flux.Affine(Param(784, 128), Param(1, 128)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"matmul_3\", Any[(Flux.Affine(Param(64, 10), Param(1, 10)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"matmul_2\", Any[(Flux.Affine(Param(128, 64), Param(1, 64)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"add_3\", Any[(Flux.Affine(Param(64, 10), Param(1, 10)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"add_2\", Any[(Flux.Affine(Param(128, 64), Param(1, 64)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"placeholder\", Any[(Flux.Affine(Param(784, 128), Param(1, 128)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))]),Pair{Any,Any}(\"TensorFlow.nn.softmax\", Any[]),Pair{Any,Any}(\"matmul\", Any[(Flux.Affine(Param(784, 128), Param(1, 128)), DataFlow.Line(\"/Users/wookyoung/.julia/v0.6/Flux/src/layers/affine.jl\", 6))])…), TensorFlow.Tensor[<Tensor placeholder:1 shape=unknown dtype=Float32>], <Tensor TensorFlow.nn.softmax:1 shape=unknown dtype=Float32>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 0.101359 \n",
       " 0.117402 \n",
       " 0.0912359\n",
       " 0.0929812\n",
       " 0.107271 \n",
       " 0.0889401\n",
       " 0.091921 \n",
       " 0.0926007\n",
       " 0.109281 \n",
       " 0.107009 "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33m`invoke(f, (types...), ...)` is deprecated, use `invoke(f, Tuple{types...}, ...)` instead\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:64\u001b[22m\u001b[22m\n",
      " [2] \u001b[1m(::Flux.TF.##13#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Tensor\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mbroadcast\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Function, ::TensorFlow.Tensor\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./broadcast.jl:415\u001b[22m\u001b[22m\n",
      " [4] \u001b[1m#12\u001b[22m\u001b[22m at \u001b[1m/Users/wookyoung/.julia/v0.6/Flux/src/backend/tensorflow/model.jl:52\u001b[22m\u001b[22m [inlined]\n",
      " [5] \u001b[1m#train!#9\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64, ::Float64, ::Flux.TF.##12#16, ::TensorFlow.train.GradientDescentOptimizer, ::Function, ::Flux.TF.Model, ::Array{Tuple{Array{Float64,1},Array{Int64,1}},1}, ::Array{Tuple{Array{Float64,1},Array{Int64,1}},1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/wookyoung/.julia/v0.6/Flux/src/backend/tensorflow/model.jl:56\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m(::Flux.#kw##train!)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Flux.#train!, ::Flux.TF.Model, ::Array{Tuple{Array{Float64,1},Array{Int64,1}},1}, ::Array{Tuple{Array{Float64,1},Array{Int64,1}},1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [7] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:485\u001b[22m\u001b[22m\n",
      " [8] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/wookyoung/.julia/v0.6/IJulia/src/execute_request.jl:156\u001b[22m\u001b[22m\n",
      " [9] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/wookyoung/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [10] \u001b[1m(::IJulia.##9#12)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[6], in expression starting on line 1\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 1\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = Float32[0.101359 0.117402 0.0912359 0.0929812 0.107271 0.0889401 0.091921 0.0926007 0.109281 0.107009]\n",
      "accuracy(m, test) = 0.0986\n",
      "y = Float32[0.0961203 0.0821184 0.0890894 0.121279 0.088391 0.092387 0.081735 0.125229 0.0996388 0.124012]\n",
      "accuracy(m, test) = 0.5286\n",
      "y = Float32[0.0602504 0.0158355 0.0267886 0.729032 0.0150675 0.0162104 0.00392011 0.053222 0.0585485 0.0211245]\n",
      "accuracy(m, test) = 0.6692\n",
      "y = Float32[0.103362 0.000639083 0.0297175 0.0163969 0.187571 0.397717 0.0505212 0.0135012 0.100797 0.0997772]\n",
      "accuracy(m, test) = 0.8399\n",
      "y = Float32[0.0217005 1.58826f-6 4.30124f-5 0.00211281 0.000486789 0.967454 0.00158593 7.1386f-6 0.0061139 0.000494708]\n",
      "accuracy(m, test) = 0.8684\n",
      "y = Float32[0.000849722 0.00248931 0.0385612 0.359859 0.00182428 0.0121296 0.000147139 0.162289 0.0477493 0.374101]\n",
      "accuracy(m, test) = 0.8741\n",
      "y = Float32[0.000245754 0.000229379 0.00121345 0.991782 1.19986f-5 0.00353585 2.54625f-6 0.000881996 0.0016811 0.000416232]\n",
      "accuracy(m, test) = 0.8975\n",
      "y = Float32[2.47155f-6 0.984147 0.000677163 0.00530944 6.38091f-5 0.000509144 0.000941579 0.00027477 0.00787737 0.000197078]\n",
      "accuracy(m, test) = 0.9052\n",
      "y = Float32[8.05975f-7 1.05474f-6 5.28721f-7 1.15422f-5 9.61941f-6 1.5173f-5 1.05617f-8 0.996663 2.20789f-5 0.0032763]\n",
      "accuracy(m, test) = 0.909\n",
      "y = Float32[0.000484087 0.000151727 0.000161115 0.795613 2.08577f-5 0.179609 1.06529f-5 3.02642f-5 0.0236894 0.00022928]\n",
      "accuracy(m, test) = 0.905\n"
     ]
    }
   ],
   "source": [
    "Flux.train!(model, train, test, η = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 0.0166987  \n",
       " 4.01045f-6 \n",
       " 0.000373073\n",
       " 0.0993163  \n",
       " 2.30343f-7 \n",
       " 0.879802   \n",
       " 2.65279f-5 \n",
       " 0.00071927 \n",
       " 0.00300555 \n",
       " 5.46454f-5 "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indmax(model(data[1][1])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indmax(model(data[2][1])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using UnicodePlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[37m      Sparsity Pattern\n",
       "\u001b[39m\u001b[37m      ┌──────────────┐\u001b[39m    \n",
       "    \u001b[37m1\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[31m> 0\u001b[39m\n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⣤\u001b[39m\u001b[31m⣤\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⡶\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[34m< 0\u001b[39m\n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠻\u001b[39m\u001b[31m⢿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⡋\u001b[39m\u001b[31m⠛\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "   \u001b[37m\u001b[39m  \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⠈\u001b[39m\u001b[31m⠻\u001b[39m\u001b[31m⣷\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣄\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣀\u001b[39m\u001b[31m⣬\u001b[39m\u001b[31m⣽\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠆\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣀\u001b[39m\u001b[31m⣤\u001b[39m\u001b[31m⣶\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠿\u001b[39m\u001b[31m⠛\u001b[39m\u001b[31m⠁\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "   \u001b[37m28\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⠉\u001b[39m\u001b[31m⠉\u001b[39m\u001b[31m⠉\u001b[39m\u001b[31m⠉\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "\u001b[37m      └──────────────┘\u001b[39m    \n",
       "\u001b[37m      1\u001b[39m\u001b[37m      \u001b[39m\u001b[37m       28\n",
       "\u001b[39m\u001b[37m         nz = 166\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy(reshape(data[1][1], (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[37m      Sparsity Pattern\n",
       "\u001b[39m\u001b[37m      ┌──────────────┐\u001b[39m    \n",
       "    \u001b[37m1\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[31m> 0\u001b[39m\n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⣠\u001b[39m\u001b[31m⣾\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣤\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[34m< 0\u001b[39m\n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣠\u001b[39m\u001b[31m⣾\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠿\u001b[39m\u001b[31m⠿\u001b[39m\u001b[31m⠛\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⡄\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "   \u001b[37m\u001b[39m  \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣸\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠋\u001b[39m\u001b[31m⠉\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⡇\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⡏\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⢀\u001b[39m\u001b[31m⣴\u001b[39m\u001b[31m⡿\u001b[39m\u001b[31m⠛\u001b[39m\u001b[31m⠁\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "     \u001b[37m\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[31m⢿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⣿\u001b[39m\u001b[31m⠟\u001b[39m\u001b[31m⠋\u001b[39m\u001b[31m⠁\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "   \u001b[37m28\u001b[39m\u001b[37m │\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m⠀\u001b[39m\u001b[37m│\u001b[39m \u001b[37m\u001b[39m   \n",
       "\u001b[37m      └──────────────┘\u001b[39m    \n",
       "\u001b[37m      1\u001b[39m\u001b[37m      \u001b[39m\u001b[37m       28\n",
       "\u001b[39m\u001b[37m         nz = 176\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy(reshape(data[2][1], (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onecold(data[1][2], 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " onecold(model(data[1][1]), 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0-dev",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
